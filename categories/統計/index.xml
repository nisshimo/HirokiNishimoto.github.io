<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>統計 on 情報系学生が日本の地域問題をまとめてみた</title>
    <link>https://hirokinishimoto.github.io/categories/%E7%B5%B1%E8%A8%88/</link>
    <description>Recent content in 統計 on 情報系学生が日本の地域問題をまとめてみた</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 15 Nov 2019 13:49:41 +0900</lastBuildDate><atom:link href="https://hirokinishimoto.github.io/categories/%E7%B5%B1%E8%A8%88/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>独立と無相関</title>
      <link>https://hirokinishimoto.github.io/posts/%E7%8B%AC%E7%AB%8B%E3%81%A8%E7%84%A1%E7%9B%B8%E9%96%A2/</link>
      <pubDate>Fri, 15 Nov 2019 13:49:41 +0900</pubDate>
      
      <guid>https://hirokinishimoto.github.io/posts/%E7%8B%AC%E7%AB%8B%E3%81%A8%E7%84%A1%E7%9B%B8%E9%96%A2/</guid>
      <description>独立と無相関は似て非なる概念である。
僕自身これらの概念を混同してしまうことが多いので整理してみた。
確率変数の分散 $X$, $Y$は確率変数とする。
$X$の期待値を$\mu = E(X)$と表記する。
$X$の分散$V(X)$は下式で定義される。
$$V(X) = E{(E(X)-\mu)^2}$$
無相関の定義 確率変数$X$,$Y$の相関係数を、
$$ \rho_{XY} = \frac{COV(X,Y)}{\sqrt{V(X)}{\sqrt{V(Y)}}} $$
と定義する。
確率変数$X$,$Y$が無相関(uncorrelated)であることの定義は$\rho_{XY}=0$、つまり$COV(X,Y)=0$であることである。
独立の定義 同時確率分布において、あらゆる$x$,$y$について条件
$$f(x,Y) = g(x)h(y)$$
が成り立つなら、X, Yは互いに独立(independent)であるという。 独立のときは、上式を$g(x), h(y)$で割れば
$$g(x|y) \equiv g(x), h(y|x) \equiv h(y)$$
が得られ、Xの出方はYによらず、Yの出方はXによらないことがわかる。
独立と無相関、どちらが強い概念か 独立よりも無相関のほうが強い。 無双感は平均的な性質であって、確率分布から
$$ \rho_{XY} = \frac{COV(X,Y)}{\sqrt{V(X)}{\sqrt{V(Y)}}} $$
により決まる量$\rho_{XY}$によるが、独立性は基礎の確率分布そのものによる仮定だからである。
独立ならば無相関である. $X$, $Y$が独立ならば、
$$E(XY) = E(X)E(Y)$$ が成立する。
よって、
$$COV(X,Y) = E(XY) -E(X)E(Y) = 0$$ したがって$\rho=0$となる。
逆は一般に成り立たない。</description>
    </item>
    
    <item>
      <title>AIC</title>
      <link>https://hirokinishimoto.github.io/posts/aic/</link>
      <pubDate>Tue, 29 Oct 2019 12:15:01 +0900</pubDate>
      
      <guid>https://hirokinishimoto.github.io/posts/aic/</guid>
      <description>平均対数尤度: $E(\log{L})$ モデルの最大対数尤度: $\log{L^*}$ モデルの自由度: $k$  としたとき、 $$ E(\log{L}) = \log{L}^* - k$$ の関係が成り立つと緑本に書いてあった。 ポアソン回帰の例でこの関係が本当に成り立つのか実験してみた。
ライブラリの読み込み import numpy as np import pandas as pd import matplotlib.pyplot as plt import scipy.stats as stats import japanize_matplotlib import seaborn as sns import statsmodels.api as sm 実験 bias1 = [] bias2 = [] n_rep = 100 size = 50 n_newdata = 100 for i in range(n_rep): # データの発生 x = np.random.randint(0,100,size=size) y = np.</description>
    </item>
    
  </channel>
</rss>

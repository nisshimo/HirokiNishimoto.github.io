<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge,chrome=1">
  <title>[論文]SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE &middot; 情報系学生が日本の地域問題をまとめてみた - このサイトはにっしーの備忘録に使われます</title>
  <meta name="generator" content="Hugo 0.82.1" />
  
  <meta name="description" content="このサイトはにっしーの備忘録に使われます"> 
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[論文]SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE"/>
<meta name="twitter:description" content="論文pdf
背景 小さなCNNアーキテクチャの利点  より効率的な分散学習 新しいモデルをclientにexportする際のoverheadを減らせる  より頻繁なモデルの更新も可能に   FPGAなど、メモリが限られたハードウェア上により柔軟にDeployできる  本論文のContribution  従来研究は高精度なモデルを目指したものが多い 本論文はCNNの設計空間を探索して、性能が他に劣らずかつ小さなSqueezeNetを発見、提案  ImageNetに対して、Alex-Netと同等の正答率 Alex-Netよりも50倍少ないパラメータ数 モデル圧縮により、SqueezeNetを0.5MBまで圧縮した  Alex-Netより510倍小さい      CNN設計空間の探索  探索を自動化しなかった → 設計空間の形に対するintuitionを得たい  CNNアーキテクチャの構成要素  microarchitecture   layer, moduleの構造
  macroarchitecture   入力から出力まで全体の構造microarchitectureの接続の仕方
  solver   論文では具体的な指定なし実装ではAdagradが使われがち
  hyperpalameters  CNN設計空間の探索の方針 1. 3x3Filterを1x1Filterに置き換える 2. 3x3Fileterへのinput channelの数を減らす 3. ネットワークの最後の方でDownsampleする 方針1.と2.は、accuracyを下げないようにしつつパラメータを減らす意図がある。
方針3.はパラメータが限られた中でaccuracyを最大化を狙うもの。出力層に近づくまでストライドsを小さな値に保つ。K.HeとH.Sunの研究成果を取り入れた形
SqueezeNetのアーキテクチャ Fire Module   Squeeze comvolution layer"/>

  <meta property="og:title" content="[論文]SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE" />
<meta property="og:description" content="論文pdf
背景 小さなCNNアーキテクチャの利点  より効率的な分散学習 新しいモデルをclientにexportする際のoverheadを減らせる  より頻繁なモデルの更新も可能に   FPGAなど、メモリが限られたハードウェア上により柔軟にDeployできる  本論文のContribution  従来研究は高精度なモデルを目指したものが多い 本論文はCNNの設計空間を探索して、性能が他に劣らずかつ小さなSqueezeNetを発見、提案  ImageNetに対して、Alex-Netと同等の正答率 Alex-Netよりも50倍少ないパラメータ数 モデル圧縮により、SqueezeNetを0.5MBまで圧縮した  Alex-Netより510倍小さい      CNN設計空間の探索  探索を自動化しなかった → 設計空間の形に対するintuitionを得たい  CNNアーキテクチャの構成要素  microarchitecture   layer, moduleの構造
  macroarchitecture   入力から出力まで全体の構造microarchitectureの接続の仕方
  solver   論文では具体的な指定なし実装ではAdagradが使われがち
  hyperpalameters  CNN設計空間の探索の方針 1. 3x3Filterを1x1Filterに置き換える 2. 3x3Fileterへのinput channelの数を減らす 3. ネットワークの最後の方でDownsampleする 方針1.と2.は、accuracyを下げないようにしつつパラメータを減らす意図がある。
方針3.はパラメータが限られた中でaccuracyを最大化を狙うもの。出力層に近づくまでストライドsを小さな値に保つ。K.HeとH.Sunの研究成果を取り入れた形
SqueezeNetのアーキテクチャ Fire Module   Squeeze comvolution layer" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hirokinishimoto.github.io/posts/squeezenet/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-11-15T14:57:51&#43;09:00" />
<meta property="article:modified_time" content="2019-11-15T14:57:51&#43;09:00" />



  
  <meta itemprop="name" content="[論文]SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE">
<meta itemprop="description" content="論文pdf
背景 小さなCNNアーキテクチャの利点  より効率的な分散学習 新しいモデルをclientにexportする際のoverheadを減らせる  より頻繁なモデルの更新も可能に   FPGAなど、メモリが限られたハードウェア上により柔軟にDeployできる  本論文のContribution  従来研究は高精度なモデルを目指したものが多い 本論文はCNNの設計空間を探索して、性能が他に劣らずかつ小さなSqueezeNetを発見、提案  ImageNetに対して、Alex-Netと同等の正答率 Alex-Netよりも50倍少ないパラメータ数 モデル圧縮により、SqueezeNetを0.5MBまで圧縮した  Alex-Netより510倍小さい      CNN設計空間の探索  探索を自動化しなかった → 設計空間の形に対するintuitionを得たい  CNNアーキテクチャの構成要素  microarchitecture   layer, moduleの構造
  macroarchitecture   入力から出力まで全体の構造microarchitectureの接続の仕方
  solver   論文では具体的な指定なし実装ではAdagradが使われがち
  hyperpalameters  CNN設計空間の探索の方針 1. 3x3Filterを1x1Filterに置き換える 2. 3x3Fileterへのinput channelの数を減らす 3. ネットワークの最後の方でDownsampleする 方針1.と2.は、accuracyを下げないようにしつつパラメータを減らす意図がある。
方針3.はパラメータが限られた中でaccuracyを最大化を狙うもの。出力層に近づくまでストライドsを小さな値に保つ。K.HeとH.Sunの研究成果を取り入れた形
SqueezeNetのアーキテクチャ Fire Module   Squeeze comvolution layer"><meta itemprop="datePublished" content="2019-11-15T14:57:51&#43;09:00" />
<meta itemprop="dateModified" content="2019-11-15T14:57:51&#43;09:00" />
<meta itemprop="wordCount" content="139">
<meta itemprop="keywords" content="論文," />
  <link href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/5.0.0/sanitize.min.css" rel="stylesheet">
  <link href="https://hirokinishimoto.github.io/css/application.css" rel="stylesheet">
</head>


<body>
  <header class="c-global-header">
  <div class="c-container c-container--medium">
    <div class="c-global-header__inner">
      <div class="c-global-header__primary">
        <h1 class="c-brand">
          <a href="https://hirokinishimoto.github.io">情報系学生が日本の地域問題をまとめてみた</a>
        </h1>
        <p class="c-description">このサイトはにっしーの備忘録に使われます</p>
      </div>
      <div class="c-global-header__utility">
        <button type="button" class="c-menu">
          <svg class="icon icon-menu">
            <use xlink:href="#icon-menu"></use>
            <symbol id="icon-menu" viewBox="0 0 32 32">
              <title>menu</title>
              <path d="M2 6h28v6h-28zM2 14h28v6h-28zM2 22h28v6h-28z"></path>
            </symbol>
          </svg>
        </button>
      </div>
      <div class="c-overlay">
  <div class="c-container">
    <nav class="c-global-nav">
      <div class="c-global-nav__closer">
        <svg class="icon icon-cross">
          <use xlink:href="#icon-cross"></use>
          <symbol id="icon-cross" viewBox="0 0 32 32">
            <title>cross</title>
            <path d="M31.708 25.708c-0-0-0-0-0-0l-9.708-9.708 9.708-9.708c0-0 0-0 0-0 0.105-0.105 0.18-0.227 0.229-0.357 0.133-0.356 0.057-0.771-0.229-1.057l-4.586-4.586c-0.286-0.286-0.702-0.361-1.057-0.229-0.13 0.048-0.252 0.124-0.357 0.228 0 0-0 0-0 0l-9.708 9.708-9.708-9.708c-0-0-0-0-0-0-0.105-0.104-0.227-0.18-0.357-0.228-0.356-0.133-0.771-0.057-1.057 0.229l-4.586 4.586c-0.286 0.286-0.361 0.702-0.229 1.057 0.049 0.13 0.124 0.252 0.229 0.357 0 0 0 0 0 0l9.708 9.708-9.708 9.708c-0 0-0 0-0 0-0.104 0.105-0.18 0.227-0.229 0.357-0.133 0.355-0.057 0.771 0.229 1.057l4.586 4.586c0.286 0.286 0.702 0.361 1.057 0.229 0.13-0.049 0.252-0.124 0.357-0.229 0-0 0-0 0-0l9.708-9.708 9.708 9.708c0 0 0 0 0 0 0.105 0.105 0.227 0.18 0.357 0.229 0.356 0.133 0.771 0.057 1.057-0.229l4.586-4.586c0.286-0.286 0.362-0.702 0.229-1.057-0.049-0.13-0.124-0.252-0.229-0.357z"></path>
          </symbol>
        </svg>
      </div>
      
      <div class="c-global-nav__item">
        <a class="c-link" href="https://hirokinishimoto.github.io/categories/">
          Categories
        </a>
      </div>
      
      <div class="c-global-nav__item">
        <a class="c-link" href="https://hirokinishimoto.github.io/tags/">
          Tags
        </a>
      </div>
      
    </nav>
  </div>
</div>

    </div>
  </div>
</header>


  <main class="c-main-content">
    
  <div class="p-single">
    <div class="c-container">
      <article class="c-post">
        <header class="c-post__header">
          <h1 class="c-post__title">[論文]SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE</h1>
          <div class="c-post__header__meta">
            <time class="c-pub-time" datetime=" 2019-11-15T14:57:51&#43;09:00 ">
              2019.11.15
            </time>
            
            <div class="c-tag">
              
              <a class="c-tag__item c-link" href="/tags/%E8%AB%96%E6%96%87">論文</a>
              
            </div>
            
          </div>
          
        </header>
        <div class="c-post__body">
          <p><a href="https://arxiv.org/pdf/1602.07360.pdf">論文pdf</a></p>
<h2 id="背景">背景</h2>
<h3 id="小さなcnnアーキテクチャの利点">小さなCNNアーキテクチャの利点</h3>
<ol>
<li>より効率的な分散学習</li>
<li>新しいモデルをclientにexportする際のoverheadを減らせる
<ul>
<li>より頻繁なモデルの更新も可能に</li>
</ul>
</li>
<li>FPGAなど、メモリが限られたハードウェア上により柔軟にDeployできる</li>
</ol>
<h2 id="本論文のcontribution">本論文のContribution</h2>
<ul>
<li>従来研究は高精度なモデルを目指したものが多い</li>
<li>本論文はCNNの設計空間を探索して、性能が他に劣らずかつ小さなSqueezeNetを発見、提案
<ul>
<li>ImageNetに対して、Alex-Netと同等の正答率</li>
<li>Alex-Netよりも<strong>50倍</strong>少ないパラメータ数</li>
<li>モデル圧縮により、SqueezeNetを<strong>0.5MB</strong>まで圧縮した
<ul>
<li>Alex-Netより<strong>510倍</strong>小さい</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="cnn設計空間の探索">CNN設計空間の探索</h2>
<ul>
<li>探索を自動化しなかった
→ 設計空間の形に対するintuitionを得たい</li>
</ul>
<h3 id="cnnアーキテクチャの構成要素">CNNアーキテクチャの構成要素</h3>
<ul>
<li>microarchitecture</li>
</ul>
<blockquote>
<p>layer, moduleの構造</p>
</blockquote>
<ul>
<li>macroarchitecture</li>
</ul>
<blockquote>
<p>入力から出力まで全体の構造<!-- raw HTML omitted -->
microarchitectureの接続の仕方</p>
</blockquote>
<ul>
<li>solver</li>
</ul>
<blockquote>
<p>論文では具体的な指定なし<!-- raw HTML omitted -->
実装ではAdagradが使われがち</p>
</blockquote>
<ul>
<li>hyperpalameters</li>
</ul>
<h3 id="cnn設計空間の探索の方針">CNN設計空間の探索の方針</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-md" data-lang="md"><span style="color:#66d9ef">1.</span> 3x3Filterを1x1Filterに置き換える
<span style="color:#66d9ef">2.</span> 3x3Fileterへのinput channelの数を減らす
<span style="color:#66d9ef">3.</span> ネットワークの最後の方でDownsampleする
</code></pre></div><p>方針1.と2.は、accuracyを下げないようにしつつパラメータを減らす意図がある。</p>
<p>方針3.はパラメータが限られた中でaccuracyを最大化を狙うもの。<!-- raw HTML omitted -->
出力層に近づくまでストライドsを小さな値に保つ。K.HeとH.Sunの研究成果を取り入れた形</p>
<h3 id="squeezenetのアーキテクチャ">SqueezeNetのアーキテクチャ</h3>
<h4 id="fire-module">Fire Module</h4>
<ul>
<li>
<p>Squeeze comvolution layer</p>
</li>
<li>
<p>expand layer</p>
</li>
</ul>
<!-- raw HTML omitted -->
<p>!!! 3つのハイパーパラメータ
(s_{1x1}) : Squeeze Layerのフィルター数(すべて1x1)</p>
<pre><code>\(e_{1x1}\) : Expand Layerの1x1フィルターの数

\(e_{3x3}\) : Expand Layerの3x3フィルターの数
</code></pre>
<h4 id="squeezenetの全体像">SqueezeNetの全体像</h4>
<!-- raw HTML omitted -->
<h3 id="squeezenetの性能評価">SqueezeNetの性能評価</h3>
<h4 id="alexnetを比較対象とした理由">AlexNetを比較対象とした理由</h4>
<p>モデル圧縮の方法は他の研究成果を取り入れている。
それらの研究はImageNetを学習したAlexNetを圧縮することを目的としており、本論文もAlexNetをSqueezeNetの比較対象とした。</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<ul>
<li>AlexNetと比較して50倍小さなモデルサイズを達成</li>
<li>しかもTop-1、Top5のImageNetの正答率においてAlexNetと同等or上回っている</li>
<li>圧縮率を見ると、DeepCompressionはSqueezeNetのような、畳み込み層ばかりの既にcompactなarchitectureにも効果的であることもわかる</li>
</ul>
<h4 id="deep-compressionとは">Deep Compressionとは？</h4>
<p>本論文で詳しい言及はなし。
<a href="https://taku-buntu.hateblo.jp/entry/2019/01/16/113434">この記事</a>を参考にした。</p>
<!-- raw HTML omitted -->
<p>下の3つのパイプラインステージから成る。</p>
<ol>
<li>枝刈り（学習フェーズで必要な（重要な）接続だけを学習 ）</li>
<li>量子化（あと重み共有）</li>
<li>ハフマン符号（バイアスの偏りを有効に利用するため）</li>
</ol>
<h3 id="cnn-microarchitecture-設計空間の探索">CNN MICROARCHITECTURE 設計空間の探索</h3>
<p>探索の見通しを良くするため、hyperparameterよりも高次の、metaparameterをいくつか導入する。</p>
<p>(Squeeze Ratio(SR)) : squeeze layerとexpand layerのフィルター数の比</p>
<p>(pct_{3x3}): expand filterのfilterの総数に対する、3x3filterの数の割合</p>
<!-- raw HTML omitted -->
<p>左の実験では、(pct_{3x3} = 0.5)、右の実験では、(SR = 0.5 ) として、それぞれ(pct_{3x3})、(SR)の値を変化させた。</p>
<p>論文では、(SR=0.125) , (pct_{3x3} = 0.5)としたものをSqueezeNetとして提案している。</p>
<h3 id="cnn-macroarchitecture-設計空間の探索">CNN MACROARCHITECTURE 設計空間の探索</h3>
<h4 id="bypassを張るというアイデア">Bypassを張るというアイデア</h4>
<ul>
<li>
<p>ResNetから着想</p>
</li>
<li>
<p>ResNet同様、正則化として作用(詳しい言及なし)</p>
</li>
<li>
<p>モデルの表現能力を高めることにも寄与する(直感的に)</p>
</li>
<li>
<p>Simple bypass approach</p>
<ul>
<li>3, 5, 7, 9番目のFireModuleを飛ばす形でバイパスを繋ぐ (cf. Figure.2)</li>
<li><strong>Input channel数とOutput channel数が同じでなければならないという制約がある</strong></li>
<li>限られた場所にしかバイパスを張れない</li>
</ul>
</li>
<li>
<p>Complex bypass approach</p>
<ul>
<li>Simple bypass approachでバイパスが張れない箇所に、1x1畳込み層を持つ&quot;complex bypass&quot;を張る
<ul>
<li>1x1畳込み層のフィルター数をoutput channelの数に合わせる</li>
</ul>
</li>
<li>追加のパラメータが生じる点に注意</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li>Simple bypass approach のほうがComplex bypass approachを上回っている
<ul>
<li>この点に関する考察は特になかった</li>
<li>設計空間の形に対する直感を得ることが目的なので、こうしたらこうなった程度の議論で良しとしたのかも</li>
</ul>
</li>
</ul>

        </div>

        <footer class="c-post__footer">
          <aside class="c-share">
  <h2 class="c-share__title">Share</h2>
  <div class="c-share__list">
    <a class="c-share__list__item c-link" href="http://twitter.com/intent/tweet?text=%5b%e8%ab%96%e6%96%87%5dSQUEEZENET%3a%20ALEXNET-LEVEL%20ACCURACY%20WITH%2050X%20FEWER%20PARAMETERS%20AND%20%3c0.5MB%20MODEL%20SIZE%20%7C%20%e6%83%85%e5%a0%b1%e7%b3%bb%e5%ad%a6%e7%94%9f%e3%81%8c%e6%97%a5%e6%9c%ac%e3%81%ae%e5%9c%b0%e5%9f%9f%e5%95%8f%e9%a1%8c%e3%82%92%e3%81%be%e3%81%a8%e3%82%81%e3%81%a6%e3%81%bf%e3%81%9f%20https%3a%2f%2fhirokinishimoto.github.io%2fposts%2fsqueezenet%2f" target="_blank">
      <svg class="icon icon-twitter">
        <use xlink:href="#icon-twitter"></use>
        <symbol id="icon-twitter" viewBox="0 0 32 32">
          <title>twitter</title>
          <path d="M32 7.075c-1.175 0.525-2.444 0.875-3.769 1.031 1.356-0.813 2.394-2.1 2.887-3.631-1.269 0.75-2.675 1.3-4.169 1.594-1.2-1.275-2.906-2.069-4.794-2.069-3.625 0-6.563 2.938-6.563 6.563 0 0.512 0.056 1.012 0.169 1.494-5.456-0.275-10.294-2.888-13.531-6.862-0.563 0.969-0.887 2.1-0.887 3.3 0 2.275 1.156 4.287 2.919 5.463-1.075-0.031-2.087-0.331-2.975-0.819 0 0.025 0 0.056 0 0.081 0 3.181 2.263 5.838 5.269 6.437-0.55 0.15-1.131 0.231-1.731 0.231-0.425 0-0.831-0.044-1.237-0.119 0.838 2.606 3.263 4.506 6.131 4.563-2.25 1.762-5.075 2.813-8.156 2.813-0.531 0-1.050-0.031-1.569-0.094 2.913 1.869 6.362 2.95 10.069 2.95 12.075 0 18.681-10.006 18.681-18.681 0-0.287-0.006-0.569-0.019-0.85 1.281-0.919 2.394-2.075 3.275-3.394z"></path>
        </symbol>
      </svg>
    </a>

    <a class="c-share__list__item c-link" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fhirokinishimoto.github.io%2fposts%2fsqueezenet%2f" target="_blank">
      <svg class="icon icon-facebook">
        <use xlink:href="#icon-facebook"></use>
        <symbol id="icon-facebook" viewBox="0 0 32 32">
          <title>facebook</title>
          <path d="M19 6h5v-6h-5c-3.86 0-7 3.14-7 7v3h-4v6h4v16h6v-16h5l1-6h-6v-3c0-0.542 0.458-1 1-1z"></path>
        </symbol>
      </svg>
    </a>

    <a class="c-share__list__item" href="http://getpocket.com/edit?url=https%3a%2f%2fhirokinishimoto.github.io%2fposts%2fsqueezenet%2f" target="_blank">
      <svg class="icon icon-get-pocket">
        <use xlink:href="#icon-get-pocket"></use>
        <symbol id="icon-get-pocket" viewBox="0 0 27 28">
          <title>get-pocket</title>
          <path d="M24.453 2c1.359 0 2.422 1.094 2.422 2.438v8.109c0 7.484-5.984 13.453-13.422 13.453-7.469 0-13.453-5.969-13.453-13.453v-8.109c0-1.328 1.109-2.438 2.438-2.438h22.016zM13.453 18.625c0.469 0 0.938-0.187 1.281-0.516l6.312-6.062c0.359-0.344 0.578-0.828 0.578-1.328 0-1.016-0.828-1.844-1.844-1.844-0.484 0-0.938 0.187-1.281 0.516l-5.047 4.844-5.047-4.844c-0.344-0.328-0.797-0.516-1.266-0.516-1.016 0-1.844 0.828-1.844 1.844 0 0.5 0.203 0.984 0.562 1.328l6.328 6.062c0.328 0.328 0.797 0.516 1.266 0.516z"></path>
        </symbol>
      </svg>
    </a>
  </div>
</aside>


          <div class="c-pager">
  <ul class="c-pager__list">
    
    <li class="c-pager__list__item c-pager__list__item--prev">
      <a class="c-link" href="https://hirokinishimoto.github.io/posts/bc/" data-toggle="tooltip" data-placement="top" title="[論文]BinaryConnect: Training Deep Neural Networks with binary weights during propagations">&larr; Previous Post</a>
    </li>
     
    <li class="c-pager__list__item c-pager__list__item--next">
      <a class="c-link" href="https://hirokinishimoto.github.io/posts/mac%E7%95%AAgooglechrome%E3%81%A7%E3%83%95%E3%83%AB%E3%83%AA%E3%83%AD%E3%83%BC%E3%83%89/" data-toggle="tooltip" data-placement="top" title="Mac版Google Chromeでフルリロード">Next Post &rarr;</a>
    </li>
    
  </ul>
</div>


          

<nav class="related-articles js-related-articles">
  <h2 class="related-articles__headline">Related Contents</h2>
  <ul class="related-articles__links">
    
    <li class="related-articles__links__item js-items">
      <article class="related-article">
        <p class="related-article__stock">2019.11.15.</p>
        <p class="related-article__title">
          <a class="related-article__link" href="/posts/bc/">[論文]BinaryConnect: Training Deep Neural Networks with binary weights during propagations</a>
        </p>
        <p class="related-article__tags">
          
          <span class="related-article__tags__item">
            論文
          </span>
           </p>
      </article>
    </li>
    
    <li class="related-articles__links__item js-items">
      <article class="related-article">
        <p class="related-article__stock">2019.11.15.</p>
        <p class="related-article__title">
          <a class="related-article__link" href="/posts/mobilenets/">[論文]MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a>
        </p>
        <p class="related-article__tags">
          
          <span class="related-article__tags__item">
            論文
          </span>
           </p>
      </article>
    </li>
    
    <li class="related-articles__links__item js-items">
      <article class="related-article">
        <p class="related-article__stock">2019.11.02.</p>
        <p class="related-article__title">
          <a class="related-article__link" href="/posts/bnn/">[論文]Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to &#43;1 or −1</a>
        </p>
        <p class="related-article__tags">
          
          <span class="related-article__tags__item">
            論文
          </span>
           </p>
      </article>
    </li>
    
  </ul>
</nav>


        </footer>
        <script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": {
    "@type": "NewsArticle",
    "@id": "https:\/\/hirokinishimoto.github.io\/posts\/squeezenet\/",
    "headline": "\u003cp\u003e\u003ca href=\u0022https:\/\/arxiv.org\/pdf\/1602.07360.pdf\u0022\u003e論文pdf\u003c\/a\u003e\u003c\/p\u003e\u003ch2 id=\u0022背景\u0022\u003e背景\u003c\/h2\u003e\u003ch3 id=\u0022小さなcnnアーキテクチャの利点\u0022\u003e小さ",
    "author": "Hiroki Nishimoto",
    "publisher": {
      "@type": "Organization",
      "name": "Hiroki Nishimoto",
      "logo": "https:\/\/hirokinishimoto.github.io\/image\/logo.png",
    },
    "image": "https:\/\/hirokinishimoto.github.io",
    "datePublished": "2019-11-15"
  },
  "headline": "\u003cp\u003e\u003ca href=\u0022https:\/\/arxiv.org\/pdf\/1602.07360.pdf\u0022\u003e論文pdf\u003c\/a\u003e\u003c\/p\u003e\u003ch2 id=\u0022背景\u0022\u003e背景\u003c\/h2\u003e\u003ch3 id=\u0022小さなcnnアーキテクチャの利点\u0022\u003e小さ",
  "alternativeHeadline": "情報系学生が日本の地域問題をまとめてみた",
  "datePublished": "2019-11-15",
  "dateModified": "2019-11-15",
  "url": "https:\/\/hirokinishimoto.github.io\/posts\/squeezenet\/",
  "wordCount": "139",
  "author": {
    "@type": "Person",
    "name": "Hiroki Nishimoto"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Hiroki Nishimoto"
  },
  "image": "",
  "genre": "論文",
  "keywords": "論文",
  "description": ""
}
</script>

      </article>
    </div>
  </div>

  </main>

  <footer class="c-global-footer">
  <div class="c-container c-container--medium">
    <nav class="c-footer-nav">
      
    </nav>
    <p class="c-copy"><small></small></p>
  </div>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</footer>


  <script src="https://hirokinishimoto.github.io/js/application.js"></script>
</body>
</html>
